name: Training
inputs:
- {name: file, type: parquet}
- {name: args, type: json}
outputs:
- {name: Output, type: String}
implementation:
  container:
    image: burntt/nby-cogflow-informer:latest
    command:
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - "def training(file_path, args):\n    import sys\n    import os\n    import pandas\
      \ as pd\n    import torch\n    import numpy as np\n    import cogflow as cf\n\
      \    import json\n\n    # Load the args from the JSON file\n    with open(args,\
      \ 'r') as f:\n        args = argparse.Namespace(**json.load(f))\n\n    if args.use_gpu\
      \ and args.use_multi_gpu:\n        args.devices = args.devices.replace(' ',\
      \ '')\n        device_ids = args.devices.split(',')\n        args.device_ids\
      \ = [int(id_) for id_ in device_ids]\n        args.gpu = args.device_ids[0]\n\
      \n    data_parser = {\n        'alibaba_pod': {'data': 'processed_data.csv',\
      \ 'T': 'avg_cpu_usage', 'M': [10, 10, 10], 'S': [1, 1, 1], 'MS': [10, 10, 10]},\n\
      \    }\n\n    if args.data in data_parser.keys():\n        data_info = data_parser[args.data]\n\
      \        args.data_path = data_info['data']\n        args.target = data_info['T']\n\
      \        args.enc_in, args.dec_in, args.c_out = data_info[args.features]\n\n\
      \    args.s_layers = [int(s_l) for s_l in args.s_layers.replace(' ', '').split(',')]\n\
      \    args.detail_freq = args.freq\n    args.freq = args.freq[-1:]\n\n    print('Args\
      \ in experiment:')\n    print(args, '\\n')\n\n    # Log the system path before\
      \ appending directories\n    print(\"System path before appending directories:\"\
      )\n    print(sys.path)\n\n    # Add root and necessary directories to sys.path\n\
      \    sys.path.append('/')\n    sys.path.append('/exp')\n    sys.path.append('/models')\n\
      \    sys.path.append('/utils')\n\n    # Log the system path after appending\
      \ directories\n    print(\"System path after appending directories:\")\n   \
      \ print(sys.path)\n\n    # Log the contents of each directory for debugging\n\
      \    directories_to_check = ['/exp', '/models', '/utils', '/data']\n    for\
      \ directory in directories_to_check:\n        if os.path.isdir(directory):\n\
      \            print(f\"Contents of {directory}:\")\n            print(os.listdir(directory))\n\
      \        else:\n            print(f\"{directory} is not a directory or does\
      \ not exist.\")\n\n    # Attempt to import the required module\n    try:\n \
      \       from exp.exp_informer import Exp_Informer\n        print(\"Import successful.\"\
      )\n    except ModuleNotFoundError as e:\n        print(f\"ModuleNotFoundError:\
      \ {e}\")\n        return \"Module import failed\"\n\n    Exp = Exp_Informer\n\
      \n    cf.autolog()\n    cf.pytorch.autolog()\n    experiment_id = cf.set_experiment(\n\
      \        experiment_name=\"Custom Model Informer Time-Series\",\n    )\n   \
      \ with cf.start_run('custom_model_run_informer') as run:\n        for ii in\
      \ range(args.itr):\n            setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(\n\
      \                args.model, args.data, args.features, args.seq_len, args.label_len,\
      \ args.pred_len, args.d_model, \n                args.n_heads, args.e_layers,\
      \ args.d_layers, args.d_ff, args.attn, args.factor, args.embed, \n         \
      \       args.distil, args.mix, args.des, ii\n            )\n\n            cf.log_param(\"\
      seq_len\", args.seq_len)\n            cf.log_param(\"n_heads\", args.n_heads)\n\
      \            cf.log_param(\"enc_lay\", args.e_layers)\n            cf.log_param(\"\
      pred_len\", args.pred_len)\n            cf.log_param(\"dec_lay\", args.d_layers)\n\
      \n            exp = Exp(args)\n            print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n\
      \            model = exp.train(setting)\n            print('>>>>>>>end training\
      \ : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n\n            print('>>>>>>>testing\
      \ : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n            test_results\
      \ = exp.test(setting)\n\n            cf.log_metric(\"mae\", test_results['mae'])\n\
      \            cf.log_metric(\"mse\", test_results['mse'])\n            cf.log_metric(\"\
      rmse\", test_results['rmse'])\n            cf.log_metric(\"r2\", test_results['r2'])\n\
      \n            print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n\
      \            preds = exp.predict(setting, True)\n\n            args_file_path\
      \ = './args.txt'\n            with open(args_file_path, 'w') as f:\n       \
      \         for arg, value in vars(args).items():\n                    f.write(f\"\
      {arg}={value}\\n\")\n            artifacts = {\"args.txt\": args_file_path}\n\
      \n            device = torch.device(\"cuda\" if torch.cuda.is_available() else\
      \ \"cpu\")\n            model.to(device)\n\n            print('ARGS before signature:\
      \ ', args)\n\n            example_x_enc = torch.rand(1, args.seq_len, args.enc_in).to(device).float()\n\
      \            example_x_mark_enc = torch.rand(1, args.seq_len, 1).to(device).float()\n\
      \            example_x_dec = torch.rand(1, args.pred_len, args.dec_in).to(device).float()\n\
      \            example_x_mark_dec = torch.rand(1, args.pred_len, 1).to(device).float()\n\
      \            inputs_example = (example_x_enc, example_x_mark_enc, example_x_dec,\
      \ example_x_mark_dec)\n            output_example = model(*inputs_example)\n\
      \n            inputs_example_cpu = tuple(tensor.cpu().detach().numpy() for tensor\
      \ in inputs_example)\n            output_example_cpu = output_example.cpu().detach().numpy()\n\
      \            inputs_example_cpu_no_batch = tuple(input_array[0] for input_array\
      \ in inputs_example_cpu)\n            output_example_cpu_no_batch = output_example_cpu[0]\n\
      \n            inputs_combined = np.concatenate([input_array.flatten() for input_array\
      \ in inputs_example_cpu_no_batch], axis=-1)\n            input_df = pd.DataFrame(inputs_combined)\n\
      \n            try:\n                signature = cf.models.infer_signature(input_df,\
      \ output_example_cpu_no_batch)\n                print('Inference Signature Correctly\
      \ Saved!')\n            except Exception as e:\n                print(f\"Error\
      \ inferring signature: {e}\")\n                signature = None\n\n        \
      \    model_info = cf.pyfunc.log_model(\n                artifact_path='informer-google-trace',\n\
      \                python_model=exp,\n                artifacts=artifacts,\n \
      \               pip_requirements=[],\n                input_example=input_df,\n\
      \                signature=signature\n            )\n\n            print(f\"\
      Run_id\", run.info.run_id)\n            print(f\"Artifact_uri\", run.info.artifact_uri)\n\
      \            print(f\"Artifact_path\", run.info.artifact_uri)\n            registered_models_list\
      \ = cf.search_registered_models()\n            print(registered_models_list)\n\
      \n            print('Returned String: ', f\"{run.info.artifact_uri}/{model_info.artifact_path}\"\
      )\n    return f\"{run.info.artifact_uri}/{model_info.artifact_path}\"\n\ndef\
      \ _serialize_str(str_value: str) -> str:\n    if not isinstance(str_value, str):\n\
      \        raise TypeError('Value \"{}\" has type \"{}\" instead of str.'.format(\n\
      \            str(str_value), str(type(str_value))))\n    return str_value\n\n\
      import argparse\n_parser = argparse.ArgumentParser(prog='Training', description='')\n\
      _parser.add_argument(\"--file\", dest=\"file_path\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--args\", dest=\"args\"\
      , type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      ----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args\
      \ = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\"\
      , [])\n\n_outputs = training(**_parsed_args)\n\n_outputs = [_outputs]\n\n_output_serializers\
      \ = [\n    _serialize_str,\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
      \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
      \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    args:
    - --file
    - {inputPath: file}
    - --args
    - {inputPath: args}
    - '----output-paths'
    - {outputPath: Output}
