# -*- coding: utf-8 -*-
"""loris_pipeline (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kmiBANb0rq6l234xGkYYSVYV84rV6M8f
"""

from cogflow import *
import cogflow
from typing import Dict, List, NamedTuple


inference_json = {
    "name": "podfailure",
    "inputs": [
        {
            "name": "cpu_milli",
            "datatype": "FP64",
            "shape": [1],
            "parameters": {"content_type": "np"},
            "data": [12000.0]
        },
        {
            "name": "memory_mib",
            "datatype": "FP64",
            "shape": [1],
            "parameters": {"content_type": "np"},
            "data": [24576.0]
        },
        {
            "name": "num_gpu",
            "datatype": "FP64",
            "shape": [1],
            "parameters": {"content_type": "np"},
            "data": [1.0]
        },
        {
            "name": "gpu_milli",
            "datatype": "FP64",
            "shape": [1],
            "parameters": {"content_type": "np"},
            "data": [1000.0]
        },
        {
            "name": "creation_time",
            "datatype": "FP64",
            "shape": [1],
            "parameters": {"content_type": "np"},
            "data": [1558381.0]
        },
        {
            "name": "qos_BE",
            "datatype": "FP64",
            "shape": [1],
            "parameters": {"content_type": "np"},
            "data": [0]
        },
        {
            "name": "qos_LS",
            "datatype": "FP64",
            "shape": [1],
            "parameters": {"content_type": "np"},
            "data": [1]
        },
        {
            "name": "qos_Guaranteed",
            "datatype": "FP64",
            "shape": [1],
            "parameters": {"content_type": "np"},
            "data": [0]
        }
    ],
    "parameters": {"content_type": "pd"}
}


@cogflow.cogcomponent()
def load_dataset(name:str,dataset_path: OutputPath()) :
    from urllib.request import urlretrieve
    url=f'https://raw.githubusercontent.com/alibaba/clusterdata/master/cluster-trace-gpu-v2023/csv/{name}.csv'
    urlretrieve(url, "/tmp/csv.csv")
    import shutil
    shutil.copyfile("/tmp/csv.csv", dataset_path)
    #import cogflow
    #cogflow.get_dataset(name)
    #shutil.copyfile(f'{name}.csv', dataset_path)

@cogflow.cogcomponent()
def preprocess(dataset_path: InputPath() ,x_train_path: OutputPath() ,y_train_path: OutputPath() ,x_test_path: OutputPath(),y_test_path: OutputPath()  )->NamedTuple("datasetspecs", class_names=List):

    import pandas as pd
    import pickle


    df = pd.read_csv(dataset_path)
    y = pd.factorize(df['pod_phase'])[0]
    dummies = pd.get_dummies(df[['qos']])
    X_ = df.drop(columns=['name','pod_phase','gpu_spec','scheduled_time','deletion_time','qos']).astype('float64') #scheduled is the only col with nans and it seems identical to creation_time
    X = pd.concat([X_, dummies[['qos_BE', 'qos_LS', 'qos_Guaranteed']]], axis = 1)
    col_names = ['cpu_milli','memory_mib','num_gpu','gpu_milli','creation_time','qos_BE','qos_LS','qos_Guaranteed']

    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import train_test_split

    scaler = StandardScaler().set_output(transform="pandas")
    X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.1)
    fitted = scaler.fit(X_train)
    X_train_scaled = fitted.transform(X_train)
    X_test_scaled = fitted.transform(X_test)

    X_train_scaled.scaler=fitted
    X_test_scaled.scaler=fitted

    with open(x_train_path, "wb") as file:
        pickle.dump(X_train_scaled, file)

    with open(y_train_path, "wb") as file:
        pickle.dump(Y_train, file)

    with open(x_test_path, "wb") as file:
        pickle.dump(X_test_scaled, file)

    with open(y_test_path, "wb") as file:
        pickle.dump(Y_test, file)

    from typing import NamedTuple,List,Dict
    class_names=df.pod_phase.unique().tolist()
        #import json
    from collections import namedtuple
    outputs = namedtuple("datasetspecs",[ 'class_names'] )
    return outputs( class_names)

@cogflow.cogcomponent()
def training(modelname:str, x_train_path: InputPath(),y_train_path: InputPath(),class_names:List)->NamedTuple(
    'outputs',
    [
      ('f1', float),
      ('acc', float),
      ('mlpipeline_metrics', 'Metrics'),
      ('runid',str),
      ('modeluri',str)
    ]):

    from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, cross_val_score, cross_val_predict
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.svm import SVC
    import xgboost as xgb
    from sklearn.linear_model import LogisticRegression
    import matplotlib.pyplot as plt
    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score, f1_score
    from sklearn.utils import resample
    from collections import Counter
    import numpy as np
    from scipy.special import softmax
    import pickle

    with open(x_train_path, "rb") as file:
        x_train = pickle.load(file)

    with open(y_train_path, "rb") as file:
        y_train = pickle.load(file)

    models = {}
    models['LR']= LogisticRegression(solver='liblinear', multi_class='ovr')
    models['KNN']= KNeighborsClassifier()
    models['SVM']= SVC()
    models['XGB']= xgb.XGBClassifier()
    models['RF']= RandomForestClassifier()

    model=models[modelname]

    scoring = {'acc': 'accuracy',
               'f1': 'f1_macro'}
    results_acc = []
    results_f1 = []
    names = []
    metricsobj={}
    acc_avg=0.
    f1_avg=0.0
    model_uri=''
    runid=''

    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)
    cv_results = cross_validate(model, x_train, y_train, cv=kfold, scoring=scoring)
    score=0.0
    import cogflow as cf
    cf.set_experiment('testm')
    with cf.start_run(run_name=modelname) as run:
        metrics=[]
        acc_avg=cv_results['test_acc'].mean()*100.0
        acc_std=cv_results['test_acc'].std()*100.0
        f1_avg=cv_results['test_f1'].mean()*100.0
        f1_std=cv_results['test_f1'].std()*100.0

        model.fit(x_train,y_train)
        #register model with cognitive framewrok
        model_info=cf.log_model(
            sk_model=model,
            artifact_path="model",
            registered_model_name=modelname
         #   signature=signature
        )

        runid = run.info.run_id
        model_uri=model_info.model_uri or "runs:/{}/model".format(runid)

        metrics.append( {'name':'f1', 'numberValue':f1_avg})
        metrics.append( {'name':'f1_std', 'numberValue':f1_std})
        metrics.append( {'name':'acc', 'numberValue':acc_avg})
        metrics.append( {'name':'acc_std', 'numberValue':acc_std})


        cf.log_param('model',modelname)
        cf.log_metric('accuracy_avg',acc_avg)
        cf.log_metric('accuracy_std',acc_std)
        cf.log_metric('f1_avg',f1_avg)
        cf.log_metric('f1_std',f1_std)
        for i in range(10):
            cf.log_metric('f1',cv_results['test_f1'][i],i)
            cf.log_metric('acc',cv_results['test_acc'][i],i)

        metricsobj =   {'metrics':metrics}

    y_pred = cross_val_predict(model, x_train, y_train, cv=10)
    conf_mat = confusion_matrix(y_train, y_pred)



    from collections import namedtuple
    outputs = namedtuple("outputs",['f1','acc',
         'mlpipeline_metrics','runid','modeluri'] )
    return outputs(f1_avg,acc_avg, json.dumps(metricsobj),runid,model_uri)

@cogflow.cogcomponent( packages_to_install=['matplotlib-inline','ipython'])
def evaluate_model(modeluri:str,model_name:str,class_names:List, x_test_path: InputPath(),y_test_path: InputPath(),runid:str)->float:

    import cogflow as cf
    import pickle
    with open(x_test_path, "rb") as file:
        x_test = pickle.load(file)

    with open(y_test_path, "rb") as file:
        y_test = pickle.load(file)
    eval_data = x_test.copy(deep=True)
    eval_data["pod_phase"] = y_test
    result=0
    cf.set_experiment('testm')
    with cf.start_run(run_id=runid) as run:
        print (f"test {modeluri}",class_names)
        defaultev={
            'log_model_explainability': False,
                    'explainability_algorithm':"kernel"
                    }
        result = cf.evaluate(
            model_name=model_name,
           model_uri=modeluri,
           data=eval_data,
           targets="pod_phase",
           model_type="classifier",
           evaluators=["default"],
            evaluator_config={'default':defaultev}
       )
    res=result.metrics
    print(res)
    return res['f1_score']

@cogflow.cogcomponent()
def best_one(modelscore:List)->str:
    max=0
    print("ready")
    best_model_uri=None
    for (modelname,score) in modelscore:
        #score=modelinfo['f1_score']
        score=float(score)
        if score>max:
            max=score
            best_model=modelname
    return best_model

@cogflow.cogcomponent( packages_to_install=['matplotlib-inline','ipython','shap==0.45.1','xgboost==1.7.5','numpy==1.24.4'])
def make_ensemble(modelname:str,x_train_path: InputPath(),y_train_path: InputPath(),x_test_path: InputPath(),y_test_path: InputPath())->str:
    import cogflow
    import xgboost
    import numpy
    from sklearn.utils import resample
    from collections import Counter
    class EnsembleModel(cogflow.pyfunc.PythonModel):
        def __init__(self,modelCreator=None):
            self.members = []
            self.scores = []
            self.scaler=None
            import numpy
            import cloudpickle
            from collections import Counter
            if modelCreator is None:
                import xgboost
                modelCreator=xgboost.XGBClassifier
        def predict(self, context, testX):
            print("coming to predict2")
            yhats = [model.predict(testX) for model in self.members]
            print("coming to predict3")
            yhats = numpy.array(yhats)
            mode = [Counter(col).most_common(1)[0][0] for col in zip(*yhats)]
            return numpy.array(mode)


        def ensemble_predictions(self, subset, testX):
            yhats = [model.predict(testX) for model in subset]
            yhats = numpy.array(yhats)
            mode = [Counter(col).most_common(1)[0][0] for col in zip(*yhats)]
            return mode

        def evaluate_n_members(self, n_members, testX, testy):
            subset = self.members[:n_members]
            yhat = self.ensemble_predictions(subset, testX)
            return yhat, accuracy_score(testy, yhat), f1_score(testy, yhat, average='macro')

        def fit(self, X_train, y_train, n_splits=2):
            self.scaler=getattr(X_train, 'scaler', None)
            ix = numpy.arange(len(X_train))
            for j in range(n_splits):
                train_ix = resample(ix, replace=True, n_samples=len(X_train))
                train_ix = train_ix.astype(int)
                clf = modelCreator() #xgb.XGBClassifier()
                model = clf.fit(X_train.iloc[train_ix], y_train[train_ix])
                self.members.append(model)
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.svm import SVC
    from sklearn.linear_model import LogisticRegression
    import pickle
    modelCreatorlist={'LR': LogisticRegression,
    'KNN': KNeighborsClassifier,
    'SVM': SVC,
    'XGB': xgboost.XGBClassifier,
    'RF':RandomForestClassifier}
    modelCreator=modelCreatorlist[modelname]

    ensembleName=f'Ensemble{modelname}'
    with open(x_train_path, "rb") as file:
        x_train = pickle.load(file)
    with open(y_train_path, "rb") as file:
        y_train = pickle.load(file)
    with open(x_test_path, "rb") as file:
        x_test = pickle.load(file)
    with open(y_test_path, "rb") as file:
        y_test = pickle.load(file)
    eval_data = x_test
    eval_data["pod_phase"] = y_test

    import numpy,pandas
    print(numpy.__version__)
    print(pandas.__version__)
    #start creating enseble model
    with cogflow.start_run(run_name="Ensemble") as run:
        emodel=EnsembleModel(modelCreator=modelCreator)
        emodel.fit(x_train,y_train)

        # infer model signature
        predictions = emodel.predict(None,x_train)
        signature = cogflow.models.infer_signature(x_train,
                                                   predictions
                                                  )

        model_info=cogflow.pyfunc.log_model(
                artifact_path=ensembleName,
                python_model=emodel,
                #    pip_requirements=['shap==0.45.1','xgboost==2.0.3',],
            conda_env={
                    "name": "cogflow-env",
                    "channels": ["conda-forge"],
                    "dependencies": [
                        "python=3.9.0",
                        {
                            "pip": [
                                "shap==0.45.1",
                                "xgboost==2.0.3",
                                "cloudpickle==2.2.1",
                                "numpy==1.24.4"
                            ],
                        },
                    ],},

            registered_model_name=ensembleName,
            signature=signature
            )
        defaultev={
            'explainability_algorithm':"kernel",
            'explainability_nsamples':100
        }

        import shap
        print(shap.__version__)
        result = cogflow.evaluate(
            model_name=ensembleName,
           model_uri=model_info.model_uri,
           data=eval_data,
           targets="pod_phase",
           model_type="classifier",
           evaluators=["default"],
            evaluator_config={'default':defaultev}
               )
        return f'{run.info.artifact_uri}/{ensembleName}'

@cogflow.cogcomponent()
def serve_final_model(model_uri:str,name:str)->str:
    import cogflow as cf
    service = cf.serve_model_v2(model_uri=model_uri,name=name)
    print(service)
    return cf.get_model_url(model_name=name)

@cogflow.pipeline(name="wp3ex")
def wp3ex(datasetname:str="openb_pod_list_default")->str:
    models=['LR','KNN','SVM','XGB','RF']
    dt=load_dataset(name=datasetname)
    pdt=preprocess(dataset=dt.output)
    outputs = []
    for modelname in models:
        train_model_task = training(modelname=modelname,x_train=pdt.outputs['x_train'],y_train=pdt.outputs['y_train'],class_names=pdt.outputs['class_names'])
        train_model_task.set_display_name(f'Training {modelname}')
        test_task = evaluate_model( modeluri=train_model_task.outputs['modeluri'],
                            class_names=pdt.outputs['class_names'],
                            x_test=pdt.outputs['x_test'],
                            y_test=pdt.outputs['y_test'],
                            runid=train_model_task.outputs['runid'],
                                   model_name=modelname
                                  )
        outputs.append((modelname,test_task.output))
    bestmodel=best_one(modelscore=outputs)
    ensemblemodel=make_ensemble(modelname=bestmodel.output,x_train=pdt.outputs['x_train'],y_train=pdt.outputs['y_train'],
                            x_test=pdt.outputs['x_test'],
                            y_test=pdt.outputs['y_test'])
    servedmodel=serve_final_model(model_uri=ensemblemodel.output,name="podfailure")
    return ensemblemodel.output

client = cogflow.client()
#cogflow.compiler.Compiler().compile(pipeline_func=wp3ex, package_path='wp3ex_pipeline.yaml')
client.create_run_from_pipeline_func(
    wp3ex,
    arguments={'datasetname':"openb_pod_list_default"}
    )

cogflow.create_run_from_pipeline_func(
    pipeline_func=wp3ex
)

!curl http://podfailure.adminh.svc.cluster.local/v2/models/podfailure

!curl -H POST -H "Content-Type: application/json" http://podfailure.adminh.svc.cluster.local/v2/models/podfailure/infer  -d @./data.json

cogflow.delete_served_model('podfailure')
